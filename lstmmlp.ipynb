{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23344b7c-be29-4ac6-b3ac-3794d84ab078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed458220-3b1b-4dd2-984e-b69b9b101039",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a048c6-e52e-4130-88f0-6c79a97ee097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1392.111  1431.4233 1423.0066 1410.7123 1372.748  1386.267  1381.3723\n",
      " 1378.4746 1353.293  1335.6223 1320.3523 1333.945  1330.4126 1339.6173\n",
      " 1313.3643 1301.4497 1296.531  1299.255  1305.5079 1317.6346 1315.7377\n",
      " 1339.5693 1361.6046 1400.4777 1428.1663 1446.1556 1466.024  1468.502\n",
      " 1481.8534 1496.226  1527.27   1571.114  1624.5447 1671.1204 1719.1327\n",
      " 1754.1787 1798.2473 1819.5096 1848.9707 1861.4313 1885.8729 1900.818\n",
      " 1932.3964 1942.5647 1938.48   1895.8207 1834.9507 1790.488  1764.1803\n",
      " 1769.1963 1778.1836 1788.3136 1805.0197 1809.765  1815.3016 1811.8053\n",
      " 1816.3494 1821.587  1815.79   1808.665  1808.1364 1822.047  1845.4183\n",
      " 1864.1094 1880.1893 1881.735  1893.3247 1903.36   1933.1036 1961.5393\n",
      " 1998.0183 2023.2023 2027.2847 2009.187  1989.5627 1970.744  1982.5453\n",
      " 1994.414  2010.9124 1976.8947 1940.9207 1897.5177 1898.53   1895.3646\n",
      " 1893.88   1858.2617 1831.558  1801.2733 1768.919  1718.2664 1669.4626\n",
      " 1633.112  1615.0703 1596.0057 1562.915  1501.415 ] \n",
      " [1710.195  1691.14   1683.442  1654.2117 1636.656  1592.3174 1583.7036\n",
      " 1557.984  1537.235  1497.934  1482.0724 1491.5547 1527.9567 1532.7107\n",
      " 1544.151  1521.644  1533.1603 1533.977  1527.368  1541.3783 1530.959\n",
      " 1538.1443 1532.4626 1553.0994 1600.4711 1658.9307 1716.67   1756.294\n",
      " 1780.4303 1795.989  1854.6254 1940.4158 2073.0857 2178.6045 2270.8113\n",
      " 2308.6033 2352.1636 2391.0334 2445.7554 2487.332  2508.589  2530.0286\n",
      " 2542.0027 2572.919  2578.643  2549.811  2490.0283 2416.6257 2364.6826\n",
      " 2355.3735 2365.94   2391.7366 2376.546  2399.755  2387.814  2394.4255\n",
      " 2379.6125 2378.4973 2389.939  2400.4797 2422.448  2434.77   2437.7527\n",
      " 2429.9863 2420.2788 2421.9956 2442.479  2478.219  2520.5303 2546.2954\n",
      " 2575.9575 2591.5576 2612.9707 2606.385  2586.909  2579.0208 2580.4812\n",
      " 2595.3298 2597.0166 2608.143  2586.505  2575.536  2537.9214 2520.2278\n",
      " 2487.9087 2440.4333 2406.9849 2362.484  2312.1343 2246.6763 2158.4314\n",
      " 2079.305  2006.332  1952.4324 1903.4131 1837.034 ]\n",
      "[1687.5696 2027.2847 1296.531 ] \n",
      " [2143.9834 2612.9707 1482.0724]\n",
      "[ 5.   4.  13.   8.5] \n",
      " [ 5.  -1.   2.   0.5]\n"
     ]
    }
   ],
   "source": [
    "dataset = read_csv('clear_nj.csv')\n",
    "index   = read_csv('index.csv').values\n",
    "time    = dataset.values[:64,1:97].astype('float32')\n",
    "power   = dataset.values[:64,-7:-4].astype('float32')\n",
    "temp    = dataset.values[:64,-4:].astype('float32')\n",
    "\n",
    "# normalize features\n",
    "#归一化;归一化通常有两种：最值归一化和均值方差归一化，这里采用最值归一化\n",
    "scaler1 = MinMaxScaler(feature_range=(0.1, 0.9)).fit(time) #最大最小值归一化\n",
    "scaler2 = MinMaxScaler(feature_range=(0.1, 0.9)).fit(power) #最大最小值归一化\n",
    "scaler3 = MinMaxScaler(feature_range=(0.1, 0.9)).fit(temp) #最大最小值归一化\n",
    "# scaler1 = StandardScaler().fit(time) #最大最小值归一化\n",
    "# scaler2 = StandardScaler().fit(power) #最大最小值归一化\n",
    "# scaler3 = StandardScaler().fit(temp) #最大最小值归一化\n",
    "\n",
    "scaled_time = scaler1.fit_transform(time) #\n",
    "scaled_pow  = scaler2.fit_transform(power) #\n",
    "scaled_temp = scaler3.fit_transform(temp) #\n",
    "\n",
    "print(time[0,:], '\\n', time[-1,:])\n",
    "print(power[0,:],'\\n', power[-1,:])\n",
    "print(temp[0,:], '\\n', temp[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb074ae4-6e39-495e-8274-fb901d517e75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c833ce-35da-4e8c-9896-9e9e80b0a356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a20fc6-3d17-45ea-942e-c029c4508aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def datamap(time, power, temp, index):\n",
    "    '''\n",
    "     data: sequency \n",
    "     index: \n",
    "    '''\n",
    "    seq = np.array([])\n",
    "    for i in range(time.shape[0]):\n",
    "        seq = np.concatenate((seq, time[i,:]), axis=0)\n",
    "    \n",
    "    seq_pow = np.array([])\n",
    "    for i in range(power.shape[0]):\n",
    "        seq_pow = np.concatenate((seq_pow, power[i,:]), axis=0)\n",
    "    \n",
    "    total_x = []\n",
    "    total_y = []    \n",
    "    for m in range(1,5473):\n",
    "        pow_index = []\n",
    "        for indx in index:   \n",
    "            pow_index.append(np.squeeze(seq[-(m+indx)], axis=0))\n",
    "\n",
    "        total_x.append(np.concatenate((pow_index, seq_pow[-int((m//96)+24): -(int(m//96)+3)], temp[-int(m//96),:]), axis=0))\n",
    "        total_y.append(seq[-m]) \n",
    "        \n",
    "    return total_x, total_y #total_x(:119)——> 功率时间序列 (119:-4)——>功率最大最小均值 (-4:)温度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75d2ed1-b08d-4652-bb59-6a6607c5a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_x, total_y = datamap(scaled_time, scaled_pow, scaled_temp, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2ec290-4129-480b-87a2-4e35f552a3f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4924, 143) (548, 143)\n"
     ]
    }
   ],
   "source": [
    "indx = int(math.floor(0.9*len(total_x)))\n",
    "# seed = 1234\n",
    "# random.seed(seed)\n",
    "# random.shuffle(total_x)\n",
    "# random.seed(seed)\n",
    "# random.shuffle(total_y)   随机划分的话会报错\n",
    "\n",
    "\n",
    "train_x = np.array(total_x[: indx]).astype('float32')\n",
    "train_y = np.array(total_y[: indx]).astype('float32')\n",
    "test_x  = np.array(total_x[indx:]).astype('float32')\n",
    "test_y  = np.array(total_y[indx:]).astype('float32')\n",
    "print(train_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483574d-f1bc-46c3-a359-3b00a96efe0e",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b5cb05-17ca-454b-9871-c8ee3582ecd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class dual_model(nn.Module): #双流模型\n",
    "    def __init__(self): #参数初始化\n",
    "        super(dual_model, self).__init__() #lstm 和三个线性层\n",
    "        self.d11   = nn.Linear(16, 32) #时序 0-16\n",
    "        self.d12   = nn.Linear(16, 32) #时序 16-32\n",
    "        self.d13   = nn.Linear(17, 32) #时序 \n",
    "        self.d14   = nn.Linear(17, 32) #时序 \n",
    "        self.d15   = nn.Linear(17, 32) #时序 \n",
    "        self.d16   = nn.Linear(18, 32) #时序 \n",
    "        self.d17   = nn.Linear(17, 32) #时序 \n",
    "        \n",
    "        self.LSTM1 = nn.LSTM(32, 32, batch_first=True) #时序 通道batch是第一个维度\n",
    "        self.LSTM2 = nn.LSTM(32, 32, batch_first=True) #时序 通道batch是第一个维度\n",
    "        self.LSTM3 = nn.LSTM(32, 32, batch_first=True) #时序 通道batch是第一个维度\n",
    "        self.LSTM4 = nn.LSTM(32, 32, batch_first=True) #时序 通道batch是第一个维度\n",
    "        self.LSTM5 = nn.LSTM(32, 32, batch_first=True) #时序 通道batch是第一个维度\n",
    "        self.LSTM6 = nn.LSTM(32, 32, batch_first=True) #时序 通道batch是第一个维度\n",
    "        self.LSTM7 = nn.LSTM(32, 32, batch_first=True) #时序 通道batch是第一个维度\n",
    "\n",
    "        self.d2   = nn.Linear(21, 26) #天气\n",
    "        self.d3   = nn.Linear(4, 6) #最大最小平均功率\n",
    "        \n",
    "        self.d4   = nn.Linear(32, 32) #时序非时许融合\n",
    "        self.d5   = nn.Linear(32, 1) #时序非时许融合\n",
    "        \n",
    "        self.relu = nn.LeakyReLU() #Relu 激活函数 模型的输出限制0-1 \n",
    "        # self.tanh = nn.Tanh() #Relu 激活函数 模型的输出限制0-1 \n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "            \n",
    "    def forward(self, x1, x2, x3): #前向过程 self.d1 全局变量 两个输入对应时序与非时序\n",
    "        x11   = self.relu(self.d11(x1[:,:16]))\n",
    "        x12   = self.relu(self.d12(x1[:,16:32]))\n",
    "        x13   = self.relu(self.d13(x1[:,32:49]))\n",
    "        x14   = self.relu(self.d14(x1[:,49:66]))\n",
    "        x15   = self.relu(self.d15(x1[:,66:83]))\n",
    "        x16   = self.relu(self.d16(x1[:,83:101]))\n",
    "        x17   = self.relu(self.d17(x1[:,101:]))\n",
    "   \n",
    "        info1, (hn1, cn1) = self.LSTM1(x11) \n",
    "        info2, (hn2, cn2) = self.LSTM2(x12) \n",
    "        info3, (hn3, cn3) = self.LSTM3(x13) \n",
    "        info4, (hn4, cn4) = self.LSTM4(x14) \n",
    "        info5, (hn5, cn5) = self.LSTM5(x15) \n",
    "        info6, (hn6, cn6) = self.LSTM6(x16) \n",
    "        info7, (hn7, cn7) = self.LSTM7(x17) \n",
    "        \n",
    "        info = (info1+info2+info3+info4+info5+info6+info7)/7\n",
    "        \n",
    "        x2 = self.relu(self.d2(x2))\n",
    "        x3 = self.relu(self.d3(x3))\n",
    "        no_seq = self.relu(self.d4(torch.cat([x2, x3], dim=1)))\n",
    "        \n",
    "        fuse = torch.add(info, no_seq) #将温度信息与时序信息融合\n",
    "        \n",
    "        return self.relu(self.d5(fuse))#融合之后再经历一次线性层输出后relu函数激活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "852b34e5-d719-4e08-aaf0-3a96b20a3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = dual_model().cuda() #模型\n",
    "        self.loss  = nn.L1Loss()  #绝对值损失 mae\n",
    "        self.batch = 256 #一次喂多少个数据给模型\n",
    "        self.opt   = torch.optim.Adam(self.model.parameters(), lr=2e-5, weight_decay = 2e-5) #定义一个adam优化器 参数 学习率 \n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.opt, step_size = 150, gamma=0.99)\n",
    "        self.epochs    = 2500 #训练轮数\n",
    "        self.train_loss= [] #训练损失 为损失函数可视化准备\n",
    "        self.eval_loss = []#测试损失\n",
    "        \n",
    "    def fit(self, train_x, train_y, test_x, test_y, save_path='save/'):\n",
    "        for epoch in tqdm(range(self.epochs)): #可视化进度条\n",
    "            batch_loss = [] #一个batch的损失\n",
    "            # self.model.train() \n",
    "            lr = self.opt.param_groups[0]['lr']\n",
    "            for i in range(0, len(train_x), self.batch):\n",
    "                x1 = torch.tensor(train_x[i:i+self.batch, :118]).cuda()\n",
    "                x2 = torch.tensor(train_x[i:i+self.batch, 118:-4]).cuda()\n",
    "                x3 = torch.tensor(train_x[i:i+self.batch, -4:]).cuda()\n",
    "                y  = torch.tensor(train_y[i:i+self.batch]).unsqueeze(-1).cuda() #维度扩充\n",
    "                pred = self.model(x1, x2, x3)\n",
    "                loss = self.loss(pred, y)\n",
    "                loss.backward() #计算梯度\n",
    "                self.opt.step() #优化 \n",
    "                self.scheduler.step()\n",
    "                loss = loss.detach().cpu() \n",
    "                batch_loss.append(loss)\n",
    "                  \n",
    "            if epoch%100==0:      \n",
    "                # self.model.eval()\n",
    "                self.save_params(save_path+str(epoch)+'.model')\n",
    "                print(lr, sum(batch_loss)/len(batch_loss)) #平均batch损失\n",
    "                eval_x = test_x \n",
    "                eval_y = torch.tensor(test_y).unsqueeze(-1).cuda() #将y 从np里的数组转为张量 pytorch框架只能对张量计算\n",
    "                pred = self.pred(eval_x)\n",
    "                loss = self.loss(pred.squeeze(0), eval_y).detach().cpu()  \n",
    "                \n",
    "                self.train_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "                self.eval_loss.append(loss)\n",
    "                # self.model.train() \n",
    "                \n",
    "        \n",
    "        return self.train_loss, self.eval_loss #每一百轮的损失函数  列表\n",
    "     \n",
    "\n",
    "    def pred(self, test_x):  #预测\n",
    "        # self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x1 = torch.tensor(test_x[:,:118]).cuda()\n",
    "            x2 = torch.tensor(test_x[:,118:-4]).cuda()\n",
    "            x3 = torch.tensor(test_x[:,-4:]).cuda()\n",
    "            pred = self.model(x1, x2, x3)\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "    def evaluate(self, test_x, test_y): \n",
    "        # self.model.eval()\n",
    "        eval_loss = []\n",
    "        for i in range(len(test_y)):\n",
    "            x1 = torch.tensor(test_x[i, :118]).unsqueeze(0).cuda()\n",
    "            x2 = torch.tensor(test_x[i, 118:-4]).unsqueeze(0).cuda()\n",
    "            x3 = torch.tensor(test_x[i, -4:]).unsqueeze(0).cuda()  \n",
    "            y  = torch.tensor(test_y[i]).unsqueeze(-1).cuda()\n",
    "            pred = self.model(x1, x2, x3).squeeze(0)\n",
    "            loss = self.loss(pred, y).detach().cpu()  \n",
    "            eval_loss.append(loss)\n",
    "            \n",
    "            # eval_loss.append(loss.item()/y.item())    \n",
    "            \n",
    "        print(eval_loss)\n",
    "        perc = (sum(eval_loss)/len(eval_loss))/(sum(test_y)/len(test_y))*100 \n",
    "        # perc = (sum(eval_loss)/len(eval_loss))*100 \n",
    "\n",
    "        print('Percentage error is :', perc)\n",
    "        \n",
    "        \n",
    "    def save_params(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "    \n",
    "    def load_params(self, path):\n",
    "        self_state = self.state_dict()\n",
    "        loaded_state = torch.load(path)\n",
    "        for name, param in loaded_state.items():\n",
    "            origname = name\n",
    "            if name not in self_state:\n",
    "                name = name.replace(\"module.\", \"\")\n",
    "                if name not in self_state:\n",
    "                    print(\"%s is not in the model.\"%origname)\n",
    "                    continue\n",
    "            if self_state[name].size() != loaded_state[origname].size():\n",
    "                print(\"Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state[origname].size()))\n",
    "                continue\n",
    "            self_state[name].copy_(param)           \n",
    "          \n",
    "    \n",
    "# Create an instance of the model\n",
    "model = MyModel().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2074cd-dcb4-493a-9a51-ffd04edf11a8",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efcc5364-682c-4352-8bc2-74c7a7817ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 1/2500 [00:00<14:42,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2e-05 tensor(0.4632)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                           | 101/2500 [00:25<09:55,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7550420459979353e-05 tensor(0.1171)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▎                                                                        | 201/2500 [00:50<09:56,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5400862916103097e-05 tensor(0.0704)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                     | 301/2500 [01:15<09:09,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33794351713936e-05 tensor(0.0550)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▋                                                                  | 401/2500 [01:40<08:57,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1740735638749682e-05 tensor(0.0418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▊                                                               | 501/2500 [02:05<08:14,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0302742348476063e-05 tensor(0.0470)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▉                                                            | 601/2500 [02:29<07:59,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.950464275276211e-06 tensor(0.0456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▏                                                        | 701/2500 [02:55<07:29,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.854220567156095e-06 tensor(0.0425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████▎                                                     | 801/2500 [03:19<06:58,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.89224366695035e-06 tensor(0.0380)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████▍                                                  | 901/2500 [03:44<06:34,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.987607826246625e-06 tensor(0.0287)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████▏                                              | 1001/2500 [04:09<06:16,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.254251745004564e-06 tensor(0.0228)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████▎                                           | 1101/2500 [04:33<05:49,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.610716366370519e-06 tensor(0.0243)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████▍                                        | 1201/2500 [04:58<05:21,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.005540537149785e-06 tensor(0.0204)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████▌                                     | 1301/2500 [05:22<04:54,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5149460298235142e-06 tensor(0.0198)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████▋                                  | 1401/2500 [05:47<04:32,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.084439035876891e-06 tensor(0.0184)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████▊                               | 1501/2500 [06:12<04:16,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6795934971592335e-06 tensor(0.0181)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████████████▉                            | 1601/2500 [06:36<03:49,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3513996268485527e-06 tensor(0.0171)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████████                         | 1701/2500 [07:01<03:23,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0634026060315337e-06 tensor(0.0166)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████████████████████████████████████▏                     | 1801/2500 [07:26<02:52,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7925723740464923e-06 tensor(0.0163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████▎                  | 1901/2500 [07:51<02:27,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.573019943472966e-06 tensor(0.0159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▍               | 2001/2500 [08:15<02:03,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.380358069994176e-06 tensor(0.0156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████████████████████▌            | 2101/2500 [08:40<01:39,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1991802934293088e-06 tensor(0.0153)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████▋         | 2201/2500 [09:05<01:13,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0523059178502892e-06 tensor(0.0150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 2301/2500 [09:29<00:50,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.234205655398535e-07 tensor(0.0148)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████▉   | 2401/2500 [09:54<00:24,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.022177497375096e-07 tensor(0.0147)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2500/2500 [10:18<00:00,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loss, eval_loss = model.fit(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6363b4c1-84e9-4942-956f-f4fd58b9b5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0767553114721815"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0147/(sum(test_y)/len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1a504-68ad-44d4-b32e-3d1e2777c50d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b58aa92-1605-4944-9a38-5f917087be43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, color='b', label='train_loss', linewidth=0.8) #训练\n",
    "plt.plot(eval_loss, color='y', label='eval_loss', linewidth=0.8) #测试\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc51e4f-df1e-4f19-a849-4d2503eb00b6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7659624-7057-4922-81c8-1f7e5dc974f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_params('save/2400.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bcfdfc1-4853-4422-9fd2-f53a1e4c7d93",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.0037), tensor(0.0049), tensor(0.0324), tensor(0.0561), tensor(0.0721), tensor(0.0792), tensor(0.0782), tensor(0.0545), tensor(0.0450), tensor(0.0340), tensor(0.0358), tensor(0.0240), tensor(0.0073), tensor(0.0075), tensor(0.0175), tensor(0.0423), tensor(0.0723), tensor(0.0564), tensor(0.0594), tensor(0.0632), tensor(0.0717), tensor(0.0619), tensor(0.0583), tensor(0.0578), tensor(0.0444), tensor(0.0260), tensor(0.0197), tensor(0.0392), tensor(0.0414), tensor(0.0480), tensor(0.0227), tensor(0.0355), tensor(0.0388), tensor(0.0726), tensor(0.0631), tensor(0.0452), tensor(0.0109), tensor(0.0137), tensor(0.0308), tensor(0.0129), tensor(0.0118), tensor(0.0864), tensor(0.0946), tensor(0.1003), tensor(0.0652), tensor(0.0909), tensor(0.1123), tensor(0.0705), tensor(0.0357), tensor(0.0096), tensor(0.0514), tensor(0.0460), tensor(0.0453), tensor(0.0097), tensor(0.0447), tensor(0.0650), tensor(0.0620), tensor(0.0254), tensor(0.0203), tensor(0.0732), tensor(0.0925), tensor(0.0660), tensor(0.0830), tensor(0.0710), tensor(0.0762), tensor(0.0569), tensor(0.0370), tensor(0.0475), tensor(0.0789), tensor(0.0777), tensor(0.0481), tensor(0.0480), tensor(0.0607), tensor(0.0561), tensor(0.0637), tensor(0.0526), tensor(0.0536), tensor(0.0474), tensor(0.0409), tensor(0.0504), tensor(0.0420), tensor(0.0369), tensor(0.0261), tensor(0.0559), tensor(0.0679), tensor(0.0806), tensor(0.0694), tensor(0.0444), tensor(0.0336), tensor(0.0495), tensor(0.0795), tensor(0.0727), tensor(0.0499), tensor(0.0119), tensor(0.0245), tensor(0.0364), tensor(0.0218), tensor(0.0054), tensor(0.0260), tensor(0.0365), tensor(0.0433), tensor(0.0537), tensor(0.0498), tensor(0.0195), tensor(0.0057), tensor(0.0141), tensor(0.0072), tensor(0.0192), tensor(0.0213), tensor(0.0283), tensor(0.0003), tensor(0.0318), tensor(0.0641), tensor(0.0473), tensor(0.0341), tensor(0.0306), tensor(0.0399), tensor(0.0296), tensor(0.0169), tensor(0.0014), tensor(0.0038), tensor(0.0061), tensor(0.0013), tensor(0.0249), tensor(0.0233), tensor(0.0219), tensor(0.0038), tensor(0.0112), tensor(0.0207), tensor(0.0457), tensor(0.0545), tensor(0.0594), tensor(0.0418), tensor(0.0564), tensor(0.0240), tensor(0.0531), tensor(0.0499), tensor(0.1340), tensor(0.1497), tensor(0.1834), tensor(0.1556), tensor(0.1113), tensor(0.0895), tensor(0.0155), tensor(0.0427), tensor(0.0022), tensor(0.0002), tensor(0.0077), tensor(0.0296), tensor(0.0919), tensor(0.1488), tensor(0.1485), tensor(0.1409), tensor(0.0684), tensor(0.0728), tensor(0.1072), tensor(0.1249), tensor(0.1276), tensor(0.1379), tensor(0.1392), tensor(0.1399), tensor(0.1342), tensor(0.1046), tensor(0.0028), tensor(0.0838), tensor(0.1100), tensor(0.0716), tensor(0.0692), tensor(0.0614), tensor(0.0541), tensor(0.0547), tensor(0.0621), tensor(0.0688), tensor(0.0726), tensor(0.0622), tensor(0.0811), tensor(0.0669), tensor(0.0541), tensor(0.0399), tensor(0.0715), tensor(0.0872), tensor(0.0931), tensor(0.0869), tensor(0.0578), tensor(0.0567), tensor(0.0572), tensor(0.0964), tensor(0.0880), tensor(0.0859), tensor(0.0370), tensor(0.0031), tensor(0.0114), tensor(0.0168), tensor(0.0394), tensor(0.0650), tensor(0.0752), tensor(0.0686), tensor(0.0712), tensor(0.0493), tensor(0.0348), tensor(0.0247), tensor(0.0317), tensor(0.0393), tensor(0.0363), tensor(0.0283), tensor(0.0333), tensor(0.0584), tensor(0.0797), tensor(0.0961), tensor(0.0800), tensor(0.0753), tensor(0.0694), tensor(0.0668), tensor(0.0564), tensor(0.0478), tensor(0.0466), tensor(0.0498), tensor(0.0568), tensor(0.0676), tensor(0.0872), tensor(0.0851), tensor(0.0880), tensor(0.0682), tensor(0.0759), tensor(0.0667), tensor(0.0845), tensor(0.0882), tensor(0.0938), tensor(0.0924), tensor(0.0953), tensor(0.0907), tensor(0.0652), tensor(0.0447), tensor(0.0595), tensor(0.0678), tensor(0.0949), tensor(0.0890), tensor(0.0895), tensor(0.0636), tensor(0.0020), tensor(0.0531), tensor(0.0079), tensor(0.0262), tensor(0.0396), tensor(0.0985), tensor(0.1386), tensor(0.1693), tensor(0.1298), tensor(0.1354), tensor(0.0561), tensor(0.0615), tensor(0.0903), tensor(0.1049), tensor(0.1432), tensor(0.1362), tensor(0.1425), tensor(0.1089), tensor(0.1231), tensor(0.0876), tensor(0.0170), tensor(0.1223), tensor(0.1138), tensor(0.0610), tensor(0.0644), tensor(0.0742), tensor(0.0691), tensor(0.0659), tensor(0.0682), tensor(0.0758), tensor(0.0748), tensor(0.0609), tensor(0.0664), tensor(0.0593), tensor(0.0523), tensor(0.0547), tensor(0.0950), tensor(0.1034), tensor(0.1061), tensor(0.0915), tensor(0.0645), tensor(0.0507), tensor(0.0414), tensor(0.0790), tensor(0.0771), tensor(0.0827), tensor(0.0450), tensor(0.0030), tensor(0.0051), tensor(0.0360), tensor(0.0654), tensor(0.0906), tensor(0.0929), tensor(0.0923), tensor(0.0930), tensor(0.0730), tensor(0.0519), tensor(0.0508), tensor(0.0648), tensor(0.0885), tensor(0.0885), tensor(0.0833), tensor(0.0823), tensor(0.0850), tensor(0.0935), tensor(0.0950), tensor(0.0804), tensor(0.0652), tensor(0.0557), tensor(0.0494), tensor(0.0509), tensor(0.0503), tensor(0.0569), tensor(0.0674), tensor(0.0826), tensor(0.0855), tensor(0.0933), tensor(0.0824), tensor(0.0981), tensor(0.0838), tensor(0.0984), tensor(0.0857), tensor(0.1014), tensor(0.1104), tensor(0.1112), tensor(0.0973), tensor(0.0784), tensor(0.0953), tensor(0.1042), tensor(0.0830), tensor(0.0977), tensor(0.0714), tensor(0.0848), tensor(0.0305), tensor(0.0841), tensor(0.0331), tensor(0.0411), tensor(0.0172), tensor(0.0259), tensor(0.0136), tensor(0.0101), tensor(0.0571), tensor(0.1407), tensor(0.1352), tensor(0.1203), tensor(0.1199), tensor(0.0575), tensor(0.0702), tensor(0.0754), tensor(0.0874), tensor(0.0740), tensor(0.0489), tensor(0.0810), tensor(0.0737), tensor(0.1029), tensor(0.0620), tensor(0.0335), tensor(0.1152), tensor(0.0888), tensor(0.0374), tensor(0.0446), tensor(0.0529), tensor(0.0522), tensor(0.0553), tensor(0.0733), tensor(0.0764), tensor(0.0677), tensor(0.0575), tensor(0.0752), tensor(0.0759), tensor(0.0713), tensor(0.0575), tensor(0.0841), tensor(0.0791), tensor(0.0935), tensor(0.0859), tensor(0.0714), tensor(0.0569), tensor(0.0554), tensor(0.0961), tensor(0.0966), tensor(0.1026), tensor(0.0757), tensor(0.0369), tensor(0.0387), tensor(0.0491), tensor(0.0673), tensor(0.0868), tensor(0.0908), tensor(0.0967), tensor(0.1003), tensor(0.0786), tensor(0.0665), tensor(0.0672), tensor(0.0899), tensor(0.0977), tensor(0.0944), tensor(0.0874), tensor(0.0888), tensor(0.0873), tensor(0.0896), tensor(0.0937), tensor(0.0877), tensor(0.0817), tensor(0.0746), tensor(0.0693), tensor(0.0771), tensor(0.0831), tensor(0.0891), tensor(0.0905), tensor(0.0962), tensor(0.0903), tensor(0.1055), tensor(0.1021), tensor(0.1204), tensor(0.0954), tensor(0.1040), tensor(0.0891), tensor(0.1114), tensor(0.1106), tensor(0.1065), tensor(0.0720), tensor(0.0458), tensor(0.0906), tensor(0.1063), tensor(0.0895), tensor(0.0751), tensor(0.0539), tensor(0.0407), tensor(0.0137), tensor(0.0396), tensor(0.0396), tensor(0.0254), tensor(0.0096), tensor(0.0200), tensor(0.0220), tensor(0.0109), tensor(0.0154), tensor(0.0782), tensor(0.0716), tensor(0.0647), tensor(0.0983), tensor(0.0168), tensor(0.0329), tensor(0.0374), tensor(0.0726), tensor(0.0101), tensor(0.0104), tensor(0.0132), tensor(0.0458), tensor(0.0632), tensor(0.0307), tensor(0.0941), tensor(0.0951), tensor(0.0565), tensor(0.0108), tensor(0.0155), tensor(0.0391), tensor(0.0446), tensor(0.0575), tensor(0.0674), tensor(0.0710), tensor(0.0518), tensor(0.0534), tensor(0.0594), tensor(0.0638), tensor(0.0486), tensor(0.0471), tensor(0.0741), tensor(0.0751), tensor(0.0860), tensor(0.0820), tensor(0.0654), tensor(0.0497), tensor(0.0440), tensor(0.0780), tensor(0.0817), tensor(0.0801), tensor(0.0615), tensor(0.0260), tensor(0.0319), tensor(0.0394), tensor(0.0456), tensor(0.0661), tensor(0.0625), tensor(0.0827), tensor(0.0875), tensor(0.0798), tensor(0.0587), tensor(0.0556), tensor(0.0671), tensor(0.0739), tensor(0.0711), tensor(0.0731), tensor(0.0645), tensor(0.0692), tensor(0.0709), tensor(0.0894), tensor(0.0869), tensor(0.0758), tensor(0.0692), tensor(0.0645), tensor(0.0711), tensor(0.0725), tensor(0.0658), tensor(0.0577), tensor(0.0547), tensor(0.0487), tensor(0.0660), tensor(0.0639), tensor(0.0763), tensor(0.0552), tensor(0.0546), tensor(0.0522), tensor(0.0742), tensor(0.0887), tensor(0.0908), tensor(0.0770), tensor(0.0673), tensor(0.0859), tensor(0.0781), tensor(0.0319), tensor(0.0212), tensor(0.0097), tensor(0.0007), tensor(0.0150), tensor(0.0267), tensor(0.0490), tensor(0.0163), tensor(0.0053), tensor(0.0035), tensor(0.0239), tensor(0.0182), tensor(0.0204), tensor(0.0544), tensor(0.0739), tensor(0.0779), tensor(0.0924), tensor(0.0369), tensor(0.0382), tensor(0.0569), tensor(0.0656), tensor(0.0030), tensor(0.0265), tensor(0.0013), tensor(0.0382), tensor(0.0425), tensor(0.0086), tensor(0.1137)]\n",
      "Percentage error is : tensor(32.7916)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd8de3a-15bb-40db-a1f8-fd3e95690ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e56b6b9-74e0-4410-b815-4c347be8cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6ea5e7-328c-47be-bc37-b5ada026c96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据集大小： (64, 104)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1392.110962</td>\n",
       "      <td>1431.423299</td>\n",
       "      <td>1423.006633</td>\n",
       "      <td>1410.712321</td>\n",
       "      <td>1372.748006</td>\n",
       "      <td>1386.267008</td>\n",
       "      <td>1381.372314</td>\n",
       "      <td>1378.474650</td>\n",
       "      <td>1353.293009</td>\n",
       "      <td>...</td>\n",
       "      <td>1596.005697</td>\n",
       "      <td>1562.915039</td>\n",
       "      <td>1501.415039</td>\n",
       "      <td>1687.569635</td>\n",
       "      <td>2027.284668</td>\n",
       "      <td>1296.531006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1423.492635</td>\n",
       "      <td>1432.937866</td>\n",
       "      <td>1426.656996</td>\n",
       "      <td>1411.491794</td>\n",
       "      <td>1396.852241</td>\n",
       "      <td>1392.675117</td>\n",
       "      <td>1386.760661</td>\n",
       "      <td>1390.488335</td>\n",
       "      <td>1373.087009</td>\n",
       "      <td>...</td>\n",
       "      <td>1528.079902</td>\n",
       "      <td>1514.115017</td>\n",
       "      <td>1488.726685</td>\n",
       "      <td>1658.425721</td>\n",
       "      <td>2005.593099</td>\n",
       "      <td>1326.901218</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1430.280640</td>\n",
       "      <td>1420.543199</td>\n",
       "      <td>1413.930217</td>\n",
       "      <td>1400.394572</td>\n",
       "      <td>1400.257121</td>\n",
       "      <td>1391.048218</td>\n",
       "      <td>1384.900770</td>\n",
       "      <td>1390.057454</td>\n",
       "      <td>1375.930677</td>\n",
       "      <td>...</td>\n",
       "      <td>1515.199449</td>\n",
       "      <td>1511.032444</td>\n",
       "      <td>1500.180990</td>\n",
       "      <td>1667.856226</td>\n",
       "      <td>1994.833442</td>\n",
       "      <td>1327.609795</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1422.384969</td>\n",
       "      <td>1419.095649</td>\n",
       "      <td>1420.381443</td>\n",
       "      <td>1403.464111</td>\n",
       "      <td>1406.665989</td>\n",
       "      <td>1385.270983</td>\n",
       "      <td>1384.153998</td>\n",
       "      <td>1378.939575</td>\n",
       "      <td>1367.141574</td>\n",
       "      <td>...</td>\n",
       "      <td>1523.640557</td>\n",
       "      <td>1508.972887</td>\n",
       "      <td>1482.254313</td>\n",
       "      <td>1693.898704</td>\n",
       "      <td>2030.042006</td>\n",
       "      <td>1327.427897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1423.677328</td>\n",
       "      <td>1427.221544</td>\n",
       "      <td>1432.587104</td>\n",
       "      <td>1424.418769</td>\n",
       "      <td>1420.740994</td>\n",
       "      <td>1401.911092</td>\n",
       "      <td>1398.999213</td>\n",
       "      <td>1396.804335</td>\n",
       "      <td>1392.359239</td>\n",
       "      <td>...</td>\n",
       "      <td>1551.838338</td>\n",
       "      <td>1529.568888</td>\n",
       "      <td>1500.319336</td>\n",
       "      <td>1721.773081</td>\n",
       "      <td>2054.819783</td>\n",
       "      <td>1347.431912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            0            1            2            3  \\\n",
       "0           0  1392.110962  1431.423299  1423.006633  1410.712321   \n",
       "1           1  1423.492635  1432.937866  1426.656996  1411.491794   \n",
       "2           2  1430.280640  1420.543199  1413.930217  1400.394572   \n",
       "3           3  1422.384969  1419.095649  1420.381443  1403.464111   \n",
       "4           4  1423.677328  1427.221544  1432.587104  1424.418769   \n",
       "\n",
       "             4            5            6            7            8  ...  \\\n",
       "0  1372.748006  1386.267008  1381.372314  1378.474650  1353.293009  ...   \n",
       "1  1396.852241  1392.675117  1386.760661  1390.488335  1373.087009  ...   \n",
       "2  1400.257121  1391.048218  1384.900770  1390.057454  1375.930677  ...   \n",
       "3  1406.665989  1385.270983  1384.153998  1378.939575  1367.141574  ...   \n",
       "4  1420.740994  1401.911092  1398.999213  1396.804335  1392.359239  ...   \n",
       "\n",
       "            93           94           95           96           97  \\\n",
       "0  1596.005697  1562.915039  1501.415039  1687.569635  2027.284668   \n",
       "1  1528.079902  1514.115017  1488.726685  1658.425721  2005.593099   \n",
       "2  1515.199449  1511.032444  1500.180990  1667.856226  1994.833442   \n",
       "3  1523.640557  1508.972887  1482.254313  1693.898704  2030.042006   \n",
       "4  1551.838338  1529.568888  1500.319336  1721.773081  2054.819783   \n",
       "\n",
       "            98   99  100   101   102  \n",
       "0  1296.531006  5.0  4.0  13.0   8.5  \n",
       "1  1326.901218  6.0  6.0  16.0  11.0  \n",
       "2  1327.609795  7.0  5.0  14.0   9.5  \n",
       "3  1327.427897  1.0  2.0  16.0   9.0  \n",
       "4  1347.431912  2.0  6.0  21.0  13.5  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入原始数据\n",
    "rawData = pd.read_csv('clear_nj.csv')\n",
    "print(\"原始数据集大小：\",rawData.shape)\n",
    "rawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88547eb-8b60-42f1-bdd7-db2b32fe321d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.878602</td>\n",
       "      <td>-1.408746</td>\n",
       "      <td>-1.383479</td>\n",
       "      <td>-1.316110</td>\n",
       "      <td>1372.748006</td>\n",
       "      <td>1386.267008</td>\n",
       "      <td>1381.372314</td>\n",
       "      <td>1378.474650</td>\n",
       "      <td>1353.293009</td>\n",
       "      <td>...</td>\n",
       "      <td>1596.005697</td>\n",
       "      <td>1562.915039</td>\n",
       "      <td>1501.415039</td>\n",
       "      <td>1687.569635</td>\n",
       "      <td>2027.284668</td>\n",
       "      <td>1296.531006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.513178</td>\n",
       "      <td>-1.389328</td>\n",
       "      <td>-1.334263</td>\n",
       "      <td>-1.305256</td>\n",
       "      <td>1396.852241</td>\n",
       "      <td>1392.675117</td>\n",
       "      <td>1386.760661</td>\n",
       "      <td>1390.488335</td>\n",
       "      <td>1373.087009</td>\n",
       "      <td>...</td>\n",
       "      <td>1528.079902</td>\n",
       "      <td>1514.115017</td>\n",
       "      <td>1488.726685</td>\n",
       "      <td>1658.425721</td>\n",
       "      <td>2005.593099</td>\n",
       "      <td>1326.901218</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.434135</td>\n",
       "      <td>-1.548239</td>\n",
       "      <td>-1.505851</td>\n",
       "      <td>-1.459778</td>\n",
       "      <td>1400.257121</td>\n",
       "      <td>1391.048218</td>\n",
       "      <td>1384.900770</td>\n",
       "      <td>1390.057454</td>\n",
       "      <td>1375.930677</td>\n",
       "      <td>...</td>\n",
       "      <td>1515.199449</td>\n",
       "      <td>1511.032444</td>\n",
       "      <td>1500.180990</td>\n",
       "      <td>1667.856226</td>\n",
       "      <td>1994.833442</td>\n",
       "      <td>1327.609795</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.526076</td>\n",
       "      <td>-1.566798</td>\n",
       "      <td>-1.418873</td>\n",
       "      <td>-1.417037</td>\n",
       "      <td>1406.665989</td>\n",
       "      <td>1385.270983</td>\n",
       "      <td>1384.153998</td>\n",
       "      <td>1378.939575</td>\n",
       "      <td>1367.141574</td>\n",
       "      <td>...</td>\n",
       "      <td>1523.640557</td>\n",
       "      <td>1508.972887</td>\n",
       "      <td>1482.254313</td>\n",
       "      <td>1693.898704</td>\n",
       "      <td>2030.042006</td>\n",
       "      <td>1327.427897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.511027</td>\n",
       "      <td>-1.462617</td>\n",
       "      <td>-1.254311</td>\n",
       "      <td>-1.125255</td>\n",
       "      <td>1420.740994</td>\n",
       "      <td>1401.911092</td>\n",
       "      <td>1398.999213</td>\n",
       "      <td>1396.804335</td>\n",
       "      <td>1392.359239</td>\n",
       "      <td>...</td>\n",
       "      <td>1551.838338</td>\n",
       "      <td>1529.568888</td>\n",
       "      <td>1500.319336</td>\n",
       "      <td>1721.773081</td>\n",
       "      <td>2054.819783</td>\n",
       "      <td>1347.431912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3            4  \\\n",
       "0           0 -1.878602 -1.408746 -1.383479 -1.316110  1372.748006   \n",
       "1           1 -1.513178 -1.389328 -1.334263 -1.305256  1396.852241   \n",
       "2           2 -1.434135 -1.548239 -1.505851 -1.459778  1400.257121   \n",
       "3           3 -1.526076 -1.566798 -1.418873 -1.417037  1406.665989   \n",
       "4           4 -1.511027 -1.462617 -1.254311 -1.125255  1420.740994   \n",
       "\n",
       "             5            6            7            8  ...           93  \\\n",
       "0  1386.267008  1381.372314  1378.474650  1353.293009  ...  1596.005697   \n",
       "1  1392.675117  1386.760661  1390.488335  1373.087009  ...  1528.079902   \n",
       "2  1391.048218  1384.900770  1390.057454  1375.930677  ...  1515.199449   \n",
       "3  1385.270983  1384.153998  1378.939575  1367.141574  ...  1523.640557   \n",
       "4  1401.911092  1398.999213  1396.804335  1392.359239  ...  1551.838338   \n",
       "\n",
       "            94           95           96           97           98   99  100  \\\n",
       "0  1562.915039  1501.415039  1687.569635  2027.284668  1296.531006  5.0  4.0   \n",
       "1  1514.115017  1488.726685  1658.425721  2005.593099  1326.901218  6.0  6.0   \n",
       "2  1511.032444  1500.180990  1667.856226  1994.833442  1327.609795  7.0  5.0   \n",
       "3  1508.972887  1482.254313  1693.898704  2030.042006  1327.427897  1.0  2.0   \n",
       "4  1529.568888  1500.319336  1721.773081  2054.819783  1347.431912  2.0  6.0   \n",
       "\n",
       "    101   102  \n",
       "0  13.0   8.5  \n",
       "1  16.0  11.0  \n",
       "2  14.0   9.5  \n",
       "3  16.0   9.0  \n",
       "4  21.0  13.5  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对所有数值类型的特征进行标准化处理\n",
    "# 每一个因素的均值和方差都存储到 scaled_features 变量中。\n",
    "quant_features = [ '0', '1', '2', '3']\n",
    "scaled_features = {}\n",
    "for each in quant_features:\n",
    "    mean, std = rawData[each].mean(), rawData[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    rawData.loc[:, each] = (rawData[each] - mean)/std\n",
    "rawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43129502-a00c-4bf6-927e-01ccce7516b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 104)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDataNP = rawData.values[1:4,:]\n",
    "rawDataNP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca087d63-3ad4-44e4-8c53-8bfd35371cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性核函数配置支持向量机\n",
    "linear_svr = SVR(kernel=\"linear\")\n",
    "# 训练\n",
    "linear_svr.fit(x_train, y_train)\n",
    "# 预测 保存预测结果\n",
    "linear_svr_y_predict = linear_svr.predict(x_test)\n",
    "\n",
    "plt.plot(y_test)\n",
    "plt.plot(linear_svr_y_predict)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch113",
   "language": "python",
   "name": "torch113"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
